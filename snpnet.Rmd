---
title: "MA8701: Advanced statistical methods in inference and learning"
subtitle: 'Project 1: Analysis using shrinkage methods'
author:
- name: "Janne Cathrin Hetle Aspheim"
- name: "Philip Stanley Mostert"
- name: "Kenneth Aase"
- name: "Group: JKP"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
bibliography: Bibliography.bib
biblio-style: authoryear
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Introduction

```{r load results, echo = FALSE}

load('cv_model_age1wing.RData')
load('sample_splitting_results.RData')

```

Evolutionary ecologists are interested in understanding the variation in the genetic architecture of populations of species in order to determine the traits which drive the fitness of a species. To do so, they use statistical analyses to study a significant number of single nucleotide polymorphisms (SNPs) common across a population. These SNPs represent a variation at a specific position in a DNA sequence and are indicative of the genetic diversity among individuals in the same population.

In this analysis we use SNP data collected of house sparrow (*Passer domesticus*) on 8 islands at the Helgeland coast (Norway), studied in @niskanen2020consistent. These data have been collected since 1993 and contains a wide variety of different information: pedigree, genetic alongside morphological and life-history data [@lundregan2018inferences].

For this project, we focus on studying the genetic architecture of the house sparrows, analyzing which SNPs have a significant effect on the wing length of the sparrows (at age 1). Genomic data is usually characterized by a large numbers of SNPs, which makes finding their effects on the response difficult. As a result, we will here use regularization techniques to find an optimal penalty term for our model. We then use multiple sample splitting techniques to compute the *p-values* for the effects of the SNPs. We will also correct for the effects of sex, year of measurement, island of measurement and inbreeding coefficient (`FGRM`), and these non-SNP covariates will not be penalized in the lasso.

## Prerequisites

`glmnet` [@friedman2010regularization] is a popular *R* package to fit lasso regression effectively. However, the package struggles when both the sample size and number of predictor variables is incredibly large. As a result, we use `snpnet` [@snpnet], which is a bespoke *R* package designed to fit penalizing regression methods for individual-level genetic data such as those used in this example. `snpnet` is not on CRAN, and must therefore be installed using the following instructions provided [here](https://github.com/junyangq/snpnet).

```{r snpnet, eval = FALSE}
library(devtools)

# First, install dependencies that are not on CRAN
install_github("junyangq/glmnetPlus", dependencies = TRUE)
## if this ^ does not work, run
## curl -LO http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2
## sudo tar fvxj gfortran-4.8.2-darwin13.tar.bz2 -C /
# in the terminal and then try again.


install_github("chrchang/plink-ng", subdir="/2.0/cindex", dependencies = TRUE)
install_github("chrchang/plink-ng", subdir="/2.0/pgenlibr", dependencies = TRUE)

# Now install snpnet
install_github("junyangq/snpnet", dependencies = TRUE)
```

## Data

### Genomic data

We will use the full SNP data set, in the files `Genotypes.map` and `Genotypes.ped`. We first prepare the data using PLINK v2. To run our code, you need to download the genomic data and phenotype data from @DataUsed and the program `plink2` from [here](https://www.cog-genomics.org/plink/2.0/) and put it in your working folder. We do some standard quality control steps (remove SNPs with minor allele frequency lower than $0.01$, remove SNPs missing in more than $10\%$ of individuals and remove individuals missing more than $5\%$ of the SNPs). We also change the dataset to the input format that `snpnet` needs.

```{r plink}
system2("./plink2", "--pedmap doi_10.5061_dryad.m0cfxpp10__v10/Genotypes --chr-set 32 --out sparrow_snps --maf 0.01 --geno 0.1 --mind 0.05 --make-pgen vzs")
```

Running this script shows that we have 183155 SNPs to use in our analysis. For memory reasons, the full data set will not be loaded into the *R* session, and so no graphical summary is available on them.

### Phenotype data

In this section we prepare the phenotype data (age 1 wing length).

```{r phenotype}
# Load the data
library(dplyr)

df <- read.table("doi_10.5061_dryad.m0cfxpp10__v10/Data.txt",
                 header = T)

response = "age1wing"

df2 <- select(df[!is.na(df[, response]), ], c(response, "FGRM", "gen_sex", "all_hatchyears", "fiflok"))
```

We create some columns to indicate our cross-validation splits.

```{r cv}
num_folds <- 10
df2[paste0("fold", 1:num_folds)] = NA
s <- dim(df2)[1] %>%
  seq_len() %>%
  sample() %>%
  cut(breaks = num_folds)
df2[, paste0("fold", 1:num_folds)] <-
  sapply(1:10, function(fold) ifelse(s == levels(s)[fold], "val", "train"))
```

We add the non-penalized covariates to the data.

```{r covs}
df2 <- cbind(data.frame(FID = 1, IID = df$id[!is.na(df[, response])]), df2)
df2$gen_sex <- as.factor(df2$gen_sex)
df2$all_hatchyears <- as.factor(df2$all_hatchyears)
df2$fiflok <- as.factor(df2$fiflok)
# Create dummy variables since snpnet() and plink are not as smart as lm()
X <- model.matrix(get(response) ~ gen_sex + all_hatchyears + fiflok,
                  data = df2, )[, -1]
covs <- c("FGRM", colnames(X))
df2[, covs[-1]] <- X
```

Finally, we make the phenotype file that snpnet needs.

```{r pheno_file}
write.table(df2,
            file = paste0("pheno_", response, ".txt"),
            row.names = F,
            quote = F)

```

Looking at the dimensions of our data, we see that we have 1796 observations of wing length, and around 23 covariates in the model.

```{R pheno}

dim(df2[, covs[-1]])

```

A plot of the response variable is given below.

```{r histo}

library(ggplot2)

plot(df2$IID, df2$age1wing)
abline(h= mean(df2$age1wing), col = 'red')
plot(density(df2$age1wing))

par(mfrow = c(1,3))

ggplot(data = df2, aes(y = age1wing, x = factor(gen_sex))) +
  geom_boxplot()

ggplot(data = df2, aes(y = age1wing, x = factor(all_hatchyears))) +
  geom_boxplot()

ggplot(data = df2, aes(y = age1wing, x = factor(fiflok))) +
  geom_boxplot()

ggplot(data = df2, aes(x = age1wing)) +
  geom_histogram(bins = 50) +
  ggtitle('Histogram of the wing lengths (mm)')

```

We can see that the mean of the wing lengths is `mean(df2$age1wing)`mm with a standard deviation of `sd(df2$age1wing)`mm.

## Introduction to methods

The aim of this analysis is to perform dimension reduction on the dataset to find a small subset of relevant SNPs; to do so we consider lasso regression. To define lasso regression, we let $n$ be the number of observations, $p$ be the number of covariates, and consider the standard regression setup using matrix notation:

$$
\boldsymbol{Y} = \boldsymbol{X}\boldsymbol{\beta} +\boldsymbol{\epsilon},
$$

where:

-   $\boldsymbol{Y}$ is a $n\times1$ vector of response variables (in our example the wing length),

-   $\boldsymbol{X}$ is a $n\times p$ design matrix with rows of observations and columns of covariates (in our example the SNPs),

-   $\boldsymbol{\beta}$ is a $n\times1$ vector of regression coefficients and

-   $\boldsymbol{\epsilon}$ is a $n\times1$ vector of random error.

The aim at hand is to choose a subset of $\boldsymbol{\beta}$ that exhibit the strongest effect. We do this by imposing some shrinkage term on the $\boldsymbol{\beta}$'s, such that some of them are set to $0$. We then define the lasso coefficients as ones which minimize a penalized residual sum of squares.

$$
\hat{\boldsymbol{\beta}}_{lasso} = \text{argmin}_{\boldsymbol{\beta}}\left(\frac{1}{n}\left|\left|\boldsymbol{Y} - \boldsymbol{X}\boldsymbol{\beta}\right|\right|^2_2\right)
$$

subject to $\left|\left|\boldsymbol{\beta}\right|\right|_1 \le t$. Or using Lagrangian notation gives:

$$
\hat{\boldsymbol{\beta}}_{lasso} = argmin_{\boldsymbol{\beta}}\left( \frac{1}{n}\left|\left|\boldsymbol{Y} - \boldsymbol{X}\boldsymbol{\beta}\right|\right|^2_2 - \lambda\left|\left|\boldsymbol{\beta}\right|\right|_1\right),
$$where $\lambda \ge 0$ is the term which controls shrinkage.

After performing lasso regression, we are interested in determining the statistical strength of the selected SNPs. However doing this is difficult given that lasso regression already introduces a selection procedure on the variables. As a result, we consider multiple sample splitting to obtain p-values for the SNPs selected from lasso. Multiple sample splitting is a method for constructing hypothesis tests and confidence intervals when the dimensions of the dataset are high. Full details are provided in [@dezeure2015high], and so we only show the algorithm for which to obtain the p-values below. The first step in finding corrected p-values using the single-sample splitting method, and then correcting them again using the multiple-sampling splitting procedure (which we do in order to account for the fact that the p-values selected in the former method are sensitive to the split of the data).

Single-sample splitting:

1.  Split the data in half, $I_1$ and $I_2$ where no observations are common between the two.

2.  Use $I_1$ for model selection with the lasso, with active variables $\hat{S}\left(I_1\right)$.

3.  Use the variables in $\hat{S}\left(I_1\right)$ to conduct estimation using data $I_2$ with least-squares, and find $m$ p-values for the estimated coefficients.

4.  Correct the $j^{th}$ raw p-values for multiple testing using: $P_{corr, j} = min\left(P_j * \left|S\left(I_1\right)\right|,1 \right)$.

Multiple-sample splitting:

1.  Run the single sample splitting $B$ times to obtain $P_{corr, j}^{[b]}$ for $b = 1,2,…,B$ and $j = 1,2,…,m$.

2.  Then calculate $Q_j \left({\gamma}\right) = \min \left( 1, \text{quantile}_\gamma\left(P_{corr, j}^{[b]}/\gamma \right)_{b=1}^B\right)$ , for values of $\gamma$ in $(\gamma_\text{min} , 1)$, where $\gamma_\text{min}$ is typically $0.05$.

3.  Finally, correct for trying many different values of $\gamma$ by multiplying by $(1 - \log(\gamma_\text{min}))$, to obtain the final p-values: $$
    \text{p-value}_j = \min(1, (1 - \log(\gamma_\text{min}))\cdot \min_\gamma( Q_j \left({\gamma}\right)))
    $$

## Statistical analysis

### Cross-validation for lasso parameter

When performing lasso-regression we need to choose a value for the penalization parameter $\lambda$. We use cross-validation for this. Preferably the cross-validation loop should happen inside the multiple sample-splitting procedure to generate a new $\lambda$ for each split, but in the interest of computational time we pre-compute a global $\lambda$ to be used in all splits. Below is the code for the cross-validation for $\lambda$.

```{r checkthings, echo = FALSE}

for (name in names(configs)) {
    tryCatch(system(paste(configs[[name]], "-h"), ignore.stdout = T),
             condition = function(e) cat("Please add", configs[[name]], "to PATH, or modify the path in the configs list.")
    )
}

```

```{r Lasso, echo = FALSE}
library(snpnet)

configs <- list(
    early.stopping = FALSE,
    plink2.path = "./plink2",   
    zstdcat.path = "zstdcat"
)


configs$nCores <- parallel::detectCores() - 1
configs$use.glmnetPlus <- TRUE
configs$early.stopping <- FALSE
configs$stopping.lag <- 100
configs$verbose <- FALSE

# Full solution path
full_model <- snpnet(genotype.pfile = "sparrow_snps",
                     phenotype.file = paste0("pheno_", response, ".txt"),
                     phenotype = response,
                     # Can add fixed effects here
                     covariates = covs,
                     # alpha = 1 means lasso, 0 means ridge, elastic net between
                     alpha = 1,
                     nlambda = 100, # How many values of lambda to try
                     split.col = NULL, # no validation
                     configs = configs)

# Cross-validation
result <- vector("list", num_folds)
for (k in 1:num_folds) {
  model <- snpnet(genotype.pfile = "sparrow_snps",
                  phenotype.file = paste0("pheno_", response, ".txt"),
                  phenotype = response,
                  covariates = covs, # Add fixed unpenalized effects here
                  # alpha = 1 means lasso, 0 means ridge, elastic net between
                  alpha = 1,
                  lambda = full_model$full.lams, # Check same lambdas as full
                  split.col = paste0("fold", k), # Cross-validation columns
                  configs = configs)
  result[[k]] <- model
}

# Choose best lambda
cv_metric <- rowMeans(sapply(result, function(res) res$metric.val))
opt_idx <- which.max(cv_metric) # metric: R^2 in val. set
opt_lambda <- full_model$full.lams[opt_idx]

# Non-zero betas in optimal model
opt_betas <- full_model$beta[[opt_idx]][full_model$beta[[opt_idx]] != 0]

# Save CV result
save(full_model,
     cv_metric,
     opt_idx,
     opt_lambda,
     opt_betas,
     file = paste0("cv_model_", response, ".RData"))

```

### Multiple sample splitting

Below we perform the multiple sample splitting and generate p-values.

```{r ss, echo=FALSE}

configs$early.stopping <- TRUE
B <- 1e3
p_values_split <- vector("list", B)

for (b in 1:B) {
  # Split sample in two
  split <- sample(x = df2$IID, size = round(length(df2$IID) / 2))

  # Write file for lasso-half of sample
  write.table(df2[df2$IID %in% split, ],
              file = paste0("pheno_ss_", response, ".txt"),
              row.names = F,
              quote = F)

  # Lasso-model with a given lambda
  ss_model <- snpnet(genotype.pfile = "sparrow_snps",
                     phenotype.file = paste0("pheno_ss_", response, ".txt"),
                     phenotype = response,
                     # Fixed effects
                     covariates = covs,
                     # alpha = 1 means lasso, 0 means ridge, elastic net between
                     alpha = 1,
                     lambda = opt_lambda, # Use optimal lambda
                     split.col = NULL, # cross-validation
                     configs = configs)

  # Non-zero betas
  ss_betas <-  ss_model$beta[[1]][ss_model$beta[[1]] != 0][-(1:(length(covs)))]

  # Write phenotype file for least squares half of sample
  write.table(df2[!df2$IID %in% split, ],
              file = paste0("pheno_ss!_", response, ".txt"),
              row.names = F,
              quote = F)

  # Write genomic file for least squares half of sample
  system2("./plink2",
          paste0("--pfile vzs sparrow_snps --snps ",
                 paste(substr(names(ss_betas),
                              start = 1,
                              stop = nchar(names(ss_betas)) - 2),
                       collapse = ", "),
                 " --pheno ", paste0("pheno_ss!_", response, ".txt"),
                 " --pheno-name ", response,
                 " --export A",
                 " --require-pheno ", response,
                 " --freq",
                 " --out chosen_snps"))

  # Load genomic data
  raw <- data.table::fread(file = "chosen_snps.raw",
                           drop = c(1, 3, 4, 5),
                           data.table = FALSE)
  # Load allele frequencies
  freqs <- data.table::fread(file = "chosen_snps.afreq",
                             select = "ALT_FREQS",
                             data.table = FALSE)

  # Mean imputation
  for (snp in seq_len(ncol(raw))[-(1:2)]) {
    raw[is.na(raw[, snp]), snp] <- 2 * (1 - freqs[snp - 2, ])
  }

  # Data object for linear regression
  ls_df <- cbind(df2[match(raw$IID, df2$IID), c(covs)],
                   raw[, !colnames(raw) %in% "IID"])

  # Perform linear regression
  ls_mod <- lm(PHENOTYPE ~ ., data = ls_df)
  # Save SNP p-values
  p_v <- summary(ls_mod)$coefficients[, "Pr(>|t|)"]
  p_v <- p_v[substr(names(p_v), 1, 3) == "SNP"]
  p_values_split[[b]] <- data.frame(ID = names(p_v),
                                    # Correct for multiple testing
                                    P_corr = pmin(p_v * length(p_v), 1))
  # Garbage collection
  rm(ls_mod, raw, ss_model, ls_df, p_v)
  gc()
}

# All SNPs with non-zero beta for in at least one split
atleastonce <- unique(unlist(sapply(p_values_split, function(p) p$ID)))

# Combine results from splits
p_values_split_combined <- lapply(p_values_split, function(x) {

  df <- data.frame(p_val = rep(1, length(atleastonce))) # Non-chosen p-values=1
  rownames(df) <- atleastonce

  # Record p-values for chosen SNPs
  for (snp in x$ID) {
    df$p_val[rownames(df) == snp] <- x$P_corr[x$ID == snp]
  }

  df
}) %>%
  do.call(what = cbind)

colnames(p_values_split_combined) <-
  paste0(colnames(p_values_split_combined), "_", 1:B)

# Find Q_gamma for various values of gamma (i.e. correct for multiple splitting)
gamma_min <- 0.05 # Minimum quantile we check
gamma <- seq(from = gamma_min, by = 0.01, to = 1)
Q_gamma <- as.data.frame(lapply(X = gamma,
                                FUN = function(g) {
                                  apply(X = p_values_split_combined / g,
                                        MARGIN = 1,
                                        FUN = function(x) {
                                          min(quantile(x, probs = g), 1)
                                        })}),
                         col.names = gamma,
                         row.names = atleastonce)

# Choose gamma for each SNP, and correct for the choice by multiplying
# with (1 - log(gamma_min))
P_val_final <- pmin(1, apply(as.data.frame(Q_gamma),
                             MARGIN = 1,
                             FUN = min) * (1 - log(gamma_min)))

names(P_val_final) <- atleastonce

# Save results
save(p_values_split_combined,
     Q_gamma,
     P_val_final,
     file = "sample_splitting_results.RData")

```

## Results

```{r, plot}

plot(full_model$full.lams,
     cv_metric,
     xlab = "lambda",
     ylab = "mean of 10 folds' R^2 in val. set")
abline(v = opt_lambda)

# There is one large beta for wing length
plot(opt_betas)

plot(full_model$glmnet.results[[1]])

```

## Conclusion

We don't find evidence that any of the available SNPs are related to wing length. This makes sense because of the infinitesimal model, which is a standard assumption in quantitative genetics that complex traits are determined by multiple SNPs, and very small contributions by individual SNPs. Presumably we need a larger sample size to detect the influence of individual SNPs.

## Bibliography
