---
title: "MA8701: Advanced statistical methods in inference and learning"
subtitle: 'Project 1: Analysis using shrinkage methods'
author:
- name: "Janne Cathrin Hetle Aspheim"
- name: "Philip Stanley Mostert"
- name: "Kenneth Aase"
- name: "Group: JKP"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
bibliography: Bibliography.bib
biblio-style: authoryear
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

One of the phenomenons that ecologists and genomicists may be concerned with is inbreeding depression: the decrease in fitness of organisms as a result of inbreeding within a population. This phenomenon typically occurs in small populations, lowering the population's ability to survive and reproduce, which substantially increases their risk of extinction.

A Single nucleotide polymorphism (SNP) is a variation at specific positions in a DNA sequence in living organisms.

In this analysis we use data collected of house sparrow on 18 islands at the Helgeland coast (Norway), studied in @niskanen2020consistent.

These datasets are naturally massive, which makes finding the effect of SNPs incredibly difficult.

## Prerequisites

`glmnet` [@friedman2010regularization] is a popular *R* package to fit lasso regression effectively. However the package struggles when both the sample size and number of predictor variables is incredibly large. As a result, we use `snpnet` [@snpnet], which is a bespoke *R* package designed to fit penalizing regression methods for individual-level genetic data such as those used in this example. `snpnet` is not on CRAN, and must therefore be installed using the following instructions provided [here](https://github.com/junyangq/snpnet).

```{r snpnet, eval = FALSE}
library(devtools)

# First, install dependencies that are not on CRAN
install_github("junyangq/glmnetPlus", dependencies = TRUE)
## if this ^ does not work, run 
## curl -LO http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2
## sudo tar fvxj gfortran-4.8.2-darwin13.tar.bz2 -C /
# in the terminal and then try again.


install_github("chrchang/plink-ng", subdir="/2.0/cindex", dependencies = TRUE)
install_github("chrchang/plink-ng", subdir="/2.0/pgenlibr", dependencies = TRUE)

# Now install snpnet
install_github("junyangq/snpnet", dependencies = TRUE)
```

## Data

### Genomic data

Download the genomic data from @DataUsed. We will use the full SNP data set, in the files `Genotypes.map` and `Genotypes.ped`.

We first prepare the data using PLINK v2. Download the `plink2` file from [here](https://www.cog-genomics.org/plink/2.0/) and put it in your working folder. We now do the standard quality control steps (remove SNPs with minor allele frequency lower than $0.01$, remove SNPs missing in more than $10\%$ of individuals and remove individuals missing more than $5\%$ of the SNPs). This might be unnecessary because `snpnet` does this in-built. We also change the dataset to the input format that `snpnet` needs.

```{r plink}
system2("./plink2", "--pedmap doi_10.5061_dryad.m0cfxpp10__v10/Genotypes --chr-set 32 --out sparrow_snps --maf 0.01 --geno 0.1 --mind 0.05 --make-pgen vzs")
```

### Phenotype data

```{r phenotype}
# Load the data
library(dplyr)
df <- read.table("doi_10.5061_dryad.m0cfxpp10__v10/Data.txt",
                 header = T)

response = "age1wing" # or age1tarsus, age1mass, ....

df2 <- select(df[!is.na(df[, response]), ], c(response, "FGRM", "gen_sex", "all_hatchyears", "fiflok"))

# Create CV splits
num_folds <- 10
df2[paste0("fold", 1:num_folds)] = NA
s <- dim(df2)[1] %>%
  seq_len() %>%
  sample() %>%
  cut(breaks = num_folds)
df2[, paste0("fold", 1:num_folds)] <- 
  sapply(1:10, function(fold) ifelse(s == levels(s)[fold], "val", "train"))

# Make the file that snpnet needs

df2 <- cbind(data.frame(FID = 1, IID = df$id[!is.na(df[, response])]), df2)
df2$gen_sex <- as.factor(df2$gen_sex)
df2$all_hatchyears <- as.factor(df2$all_hatchyears)
df2$fiflok <- as.factor(df2$fiflok)
# Create dummy variables since snpnet and plink are not as smart as lm()
X <- model.matrix(get(response) ~ gen_sex + all_hatchyears + fiflok,
                  data = df2, )[, -1]
covs <- c("FGRM", colnames(X))
df2[, covs[-1]] <- X

write.table(df2, 
            file = paste0("pheno_", response, ".txt"),
            row.names = F,
            quote = F)

```

## Exploratory data analysis

## Statistical analysis

Do the analysis.

```{r Lasso}
library(snpnet)

configs <- list(
    # results.dir = "PATH/TO/SAVE/DIR",  # needed when saving intermediate results
    # save = TRUE,  # save intermediate results per iteration (default FALSE)
    # nCores = 16,  # number of cores available (default 1)
    # niter = 100,  # max number of iterations (default 50)
    # prevIter = 15,  # if we want to start from some iteration saved in results.dir
    # use.glmnetPlus = TRUE,  # recommended for faster computation
    early.stopping = FALSE,  # whether to stop based on validation performance (default TRUE)
    plink2.path = "./plink2",   # path to plink2 program
    zstdcat.path = "zstdcat"  # path to zstdcat program
)

# check if the provided paths are valid
for (name in names(configs)) {
    tryCatch(system(paste(configs[[name]], "-h"), ignore.stdout = T),
             condition = function(e) cat("Please add", configs[[name]], "to PATH, or modify the path in the configs list.")
    )
}

configs$nCores <- parallel::detectCores() - 1
configs$use.glmnetPlus <- TRUE
configs$early.stopping <- FALSE # to run all lambdas in each fold
configs$stopping.lag <- 100 # to run all lambdas in each fold
configs$verbose <- FALSE # shut up

full_model <- snpnet(genotype.pfile = "sparrow_snps",
                     phenotype.file = paste0("pheno_", response, ".txt"),
                     phenotype = response,
                     # Can add fixed effects here
                     covariates = covs,
                     # alpha = 1 means lasso, 0 means ridge, elastic net between
                     alpha = 1, 
                     nlambda = 100, # could increase for finer scale
                     split.col = NULL, # no validation
                     configs = configs)

result <- vector("list", num_folds)
for (k in 1:num_folds) {
  model <- snpnet(genotype.pfile = "sparrow_snps",
                  phenotype.file = paste0("pheno_", response, ".txt"),
                  phenotype = response,
                  # Can add fixed effects here
                  covariates = covs,
                  # alpha = 1 means lasso, 0 means ridge, elastic net between
                  alpha = 1, 
                  lambda = full_model$full.lams, # make sure we check same lambdas
                  split.col = paste0("fold", k), # cross-validation
                  configs = configs)
  result[[k]] <- model
}

# Choose best lambda
cv_metric <- rowMeans(sapply(result, function(res) res$metric.val))
opt_idx <- which.max(cv_metric) # metric: R^2 in val. set
opt_lambda <- full_model$full.lams[opt_idx]

# Non-zero betas in opt. model
opt_betas <- full_model$beta[[opt_idx]][full_model$beta[[opt_idx]] != 0] 

# save result object for phillip
save(full_model,
     cv_metric, 
     opt_idx, 
     opt_lambda, 
     opt_betas,
     file = paste0("cv_model_", response, ".RData"))

```

```{r, plot}

plot(full_model$full.lams,
     cv_metric, 
     xlab = "lambda", 
     ylab = "mean of 10 folds' R^2 in val. set")
abline(v = opt_lambda)

# There is one large beta for wing length
plot(opt_betas)

plot(full_model$glmnet.results[[1]])

system2("./plink2", 
        paste0("--pfile vzs sparrow_snps --snps ",
               paste(substr(names(opt_betas),
                            start = 1,
                            stop = nchar(names(opt_betas)) - 2),
                     collapse = ", "),
               " --pheno ", paste0("pheno_", response, ".txt"),
               " --pheno-name ", response,
               " --covar ", paste0("pheno_", response, ".txt"),
               " --covar-name ", paste(covs, collapse = " "),
               " --glm hide-covar"))

lm_res <- data.table::fread(file = paste0("plink2.", response, ".glm.linear"))
p_values <- lm_res$P
```

## Conclusion

## Bibliography
